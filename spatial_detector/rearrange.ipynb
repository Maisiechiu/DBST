{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_path = \"/mnt/sdc/maisie/\"\n",
    "compression_level = \"c23\"\n",
    "output_file_path  = \"/mnt/sdb/maisie/SelfBlendedImages/data/FF++_trainwotest\"\n",
    "\n",
    "ff_dict = {\n",
    "    \"Deepfakes\": \"FF-DF\",\n",
    "    \"Face2Face\": \"FF-F2F\",\n",
    "    \"FaceSwap\": \"FF-FS\",\n",
    "    \"Real\": \"FF-real\",\n",
    "    \"NeuralTextures\": \"FF-NT\",\n",
    "    \"FaceShifter\": \"FF-FH\",\n",
    "}\n",
    "\n",
    "# Load the JSON files for data split\n",
    "dataset_path = os.path.join(dataset_root_path, \"FaceForensics++\")\n",
    "\n",
    "# Load the JSON files for data split\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(\n",
    "                dataset_path,\n",
    "                \"train.json\",\n",
    "            )),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    train_json = json.load(f)\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(dataset_path,\"val.json\")),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    val_json = json.load(f)\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(dataset_path,\"test.json\")),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    test_json = json.load(f)\n",
    "\n",
    "# Create a dictionary for searching the data split\n",
    "video_to_mode = dict()\n",
    "for d1, d2 in train_json:\n",
    "    video_to_mode[d1] = \"train\"\n",
    "    video_to_mode[d2] = \"train\"\n",
    "    video_to_mode[d1 + \"_\" + d2] = \"train\"\n",
    "    video_to_mode[d2 + \"_\" + d1] = \"train\"\n",
    "for d1, d2 in val_json:\n",
    "    video_to_mode[d1] = 'val'\n",
    "    video_to_mode[d2] = 'val'\n",
    "    video_to_mode[d1+'_'+d2] = 'val'\n",
    "    video_to_mode[d2+'_'+d1] = 'val'\n",
    "for d1, d2 in test_json:\n",
    "    video_to_mode[d1] = 'test'\n",
    "    video_to_mode[d2] = 'test'\n",
    "    video_to_mode[d1+'_'+d2] = 'test'\n",
    "    video_to_mode[d2+'_'+d1] = 'test'\n",
    "\n",
    "# Comment following to get whole FF++dataset to train\n",
    "# for d1, d2 in val_json:\n",
    "#     video_to_mode[d1] = 'val'\n",
    "#     video_to_mode[d2] = 'val'\n",
    "#     video_to_mode[d1+'_'+d2] = 'val'\n",
    "#     video_to_mode[d2+'_'+d1] = 'val'\n",
    "# for d1, d2 in test_json:\n",
    "#     video_to_mode[d1] = 'test'\n",
    "#     video_to_mode[d2] = 'test'\n",
    "#     video_to_mode[d1+'_'+d2] = 'test'\n",
    "#     video_to_mode[d2+'_'+d1] = 'test'\n",
    "\n",
    "dataset_dict = {}\n",
    "\n",
    "# FaceForensics++ real dataset\n",
    "label = \"Real\"\n",
    "dataset_dict[\"FaceForensics++\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"] = {}\n",
    "\n",
    "# Iterate over all compression levels: c23, c40, raw\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"train\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"test\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"val\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"train\"][compression_level] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"test\"][compression_level] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"val\"][compression_level] = {}\n",
    "\n",
    "# Iterate over all videos\n",
    "for video_path in os.scandir(\n",
    "        os.path.join(\n",
    "            dataset_path,\n",
    "            \"original_sequences\",\n",
    "            \"youtube\",\n",
    "            compression_level,\n",
    "            \"rawframes\",\n",
    "        )):\n",
    "    if video_path.is_dir() and 'ipynb' not in video_path.name:\n",
    "        video_name = video_path.name\n",
    "        mode = video_to_mode[video_name]\n",
    "        frame_paths = [\n",
    "            os.path.join(video_path, frame.name)\n",
    "            for frame in os.scandir(video_path) \\\n",
    "                if os.path.isfile(os.path.join(video_path, frame.name).replace('rawframes', 'landmarks').replace('png', 'npy')) and\\\n",
    "                os.path.isfile(os.path.join(video_path, frame.name).replace('rawframes', 'retina').replace('png', 'npy'))\n",
    "        ]\n",
    "\n",
    "        dataset_dict[\"FaceForensics++\"][\"FF-real\"][mode][compression_level][\n",
    "            video_name] = {\n",
    "                \"label\": ff_dict[label],\n",
    "                \"frames\": frame_paths\n",
    "            }\n",
    "\n",
    "\n",
    "# FaceForensics++ fake datasets\n",
    "for label_dir in os.scandir(os.path.join(dataset_path,\n",
    "                                         \"manipulated_sequences\")):\n",
    "    if \"youtube\" in label_dir.name or \"FaceShifter\" in label_dir.name:\n",
    "        continue\n",
    "    label = label_dir.name\n",
    "    print(label)\n",
    "    dataset_dict[\"FaceForensics++\"][ff_dict[label]] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"train\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"test\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"val\"] = {}\n",
    "\n",
    "    dataset_dict[\"FaceForensics++\"][\n",
    "        ff_dict[label]][\"train\"][compression_level] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\n",
    "        ff_dict[label]][\"test\"][compression_level] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\n",
    "        ff_dict[label]][\"val\"][compression_level] = {}\n",
    "\n",
    "    # Iterate over all videos\n",
    "    for video_path in os.scandir(\n",
    "            os.path.join(\n",
    "                dataset_path,\n",
    "                \"manipulated_sequences\",\n",
    "                label,\n",
    "                compression_level,\n",
    "                \"rawframes\",\n",
    "            )):\n",
    "        if video_path.is_dir() and 'ipynb' not in video_path.name:\n",
    "            video_name = video_path.name\n",
    "            mode = video_to_mode[video_name]\n",
    "            frame_paths = [\n",
    "                os.path.join(video_path, frame.name)\n",
    "                for frame in os.scandir(video_path) \\\n",
    "                    if os.path.isfile(os.path.join(video_path, frame.name).replace('rawframes', 'landmarks').replace('png', 'npy')) and\\\n",
    "                    os.path.isfile(os.path.join(video_path, frame.name).replace('rawframes', 'retina').replace('png', 'npy'))\n",
    "            ]\n",
    "\n",
    "            dataset_dict[\"FaceForensics++\"][ff_dict[label]][mode][compression_level][\n",
    "                video_name] = {\n",
    "                    \"label\": ff_dict[label],\n",
    "                    \"frames\": frame_paths\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for label, value in dataset_dict[\"FaceForensics++\"].items():\n",
    "    if label != \"FF-real\":\n",
    "        with open(os.path.join(output_file_path, f\"{label}.json\"),\n",
    "                    \"w\") as f:\n",
    "            data = {\n",
    "                label: {\n",
    "                    \"FF-real\": dataset_dict[\"FaceForensics++\"][\"FF-real\"],\n",
    "                    label: value,\n",
    "                }\n",
    "            }\n",
    "            json.dump(data, f)\n",
    "            print(f\"Finish writing {label}.json\")\n",
    "\n",
    "with open(os.path.join(output_file_path, \"FaceForensics++.json\"), \"w\") as f:\n",
    "    json.dump(dataset_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unseen manipulation train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralTextures\n",
      "Face2Face\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_without_Deepfakes.json\n",
      "NeuralTextures\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_without_Face2Face.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "Finish writing FaceForensics++_without_FaceSwap.json\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_without_NeuralTextures.json\n"
     ]
    }
   ],
   "source": [
    "dataset_root_path = \"/mnt/sdc/maisie/\"\n",
    "compression_level = \"c23\"\n",
    "output_file_path  = \"/mnt/sdb/maisie/SelfBlendedImages/data/FF++_trainwotest\"\n",
    "\n",
    "ff_dict = {\n",
    "    \"Deepfakes\": \"FF-DF\",\n",
    "    \"Face2Face\": \"FF-F2F\",\n",
    "    \"FaceSwap\": \"FF-FS\",\n",
    "    \"Real\": \"FF-real\",\n",
    "    \"NeuralTextures\": \"FF-NT\",\n",
    "    \"FaceShifter\": \"FF-FH\",\n",
    "}\n",
    "\n",
    "# Load the JSON files for data split\n",
    "dataset_path = os.path.join(dataset_root_path, \"FaceForensics++\")\n",
    "\n",
    "# Load the JSON files for data split\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(\n",
    "                dataset_path,\n",
    "                \"train.json\",\n",
    "            )),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    train_json = json.load(f)\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(dataset_path,\"val.json\")),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    val_json = json.load(f)\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(dataset_path,\"test.json\")),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    test_json = json.load(f)\n",
    "\n",
    "# Create a dictionary for searching the data split\n",
    "video_to_mode = dict()\n",
    "for d1, d2 in train_json:\n",
    "    video_to_mode[d1] = \"train\"\n",
    "    video_to_mode[d2] = \"train\"\n",
    "    video_to_mode[d1 + \"_\" + d2] = \"train\"\n",
    "    video_to_mode[d2 + \"_\" + d1] = \"train\"\n",
    "for d1, d2 in val_json:\n",
    "    video_to_mode[d1] = 'train'\n",
    "    video_to_mode[d2] = 'train'\n",
    "    video_to_mode[d1+'_'+d2] = 'train'\n",
    "    video_to_mode[d2+'_'+d1] = 'train'\n",
    "for d1, d2 in test_json:\n",
    "    video_to_mode[d1] = 'test'\n",
    "    video_to_mode[d2] = 'test'\n",
    "    video_to_mode[d1+'_'+d2] = 'test'\n",
    "    video_to_mode[d2+'_'+d1] = 'test'\n",
    "\n",
    "# Comment following to get whole FF++dataset to train\n",
    "# for d1, d2 in val_json:\n",
    "#     video_to_mode[d1] = 'val'\n",
    "#     video_to_mode[d2] = 'val'\n",
    "#     video_to_mode[d1+'_'+d2] = 'val'\n",
    "#     video_to_mode[d2+'_'+d1] = 'val'\n",
    "# for d1, d2 in test_json:\n",
    "#     video_to_mode[d1] = 'test'\n",
    "#     video_to_mode[d2] = 'test'\n",
    "#     video_to_mode[d1+'_'+d2] = 'test'\n",
    "#     video_to_mode[d2+'_'+d1] = 'test'\n",
    "\n",
    "\n",
    "ignore_list = [\"Deepfakes\",\"Face2Face\", \"FaceSwap\", \"NeuralTextures\"]\n",
    "for ignore in ignore_list:\n",
    "    # Iterate over all videos\n",
    "    dataset_dict = {}\n",
    "\n",
    "    # FaceForensics++ real dataset\n",
    "    label = \"Real\"\n",
    "    dataset_dict[\"FaceForensics++\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"] = {}\n",
    "\n",
    "    # Iterate over all compression levels: c23, c40, raw\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"train\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"test\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"val\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"train\"][compression_level] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"test\"][compression_level] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"val\"][compression_level] = {}\n",
    "    for video_path in os.scandir(\n",
    "            os.path.join(\n",
    "                dataset_path,\n",
    "                \"original_sequences\",\n",
    "                \"youtube\",\n",
    "                compression_level,\n",
    "                \"rawframes\",\n",
    "            )):\n",
    "        if video_path.is_dir() and 'ipynb' not in video_path.name:\n",
    "            video_name = video_path.name\n",
    "            mode = video_to_mode[video_name]\n",
    "            frame_paths = [\n",
    "                os.path.join(video_path, frame.name)\n",
    "                for frame in os.scandir(video_path) \\\n",
    "                    if os.path.isfile(os.path.join(video_path, frame.name).replace('rawframes', 'landmarks').replace('png', 'npy')) and\\\n",
    "                    os.path.isfile(os.path.join(video_path, frame.name).replace('rawframes', 'retina').replace('png', 'npy'))\n",
    "            ]\n",
    "\n",
    "            dataset_dict[\"FaceForensics++\"][\"FF-real\"][mode][compression_level][\n",
    "                video_name] = {\n",
    "                    \"label\": ff_dict[label],\n",
    "                    \"frames\": frame_paths\n",
    "                }\n",
    "\n",
    "\n",
    "    # FaceForensics++ fake datasets\n",
    "    for label_dir in os.scandir(os.path.join(dataset_path,\n",
    "                                            \"manipulated_sequences\")):\n",
    "        if \"youtube\" in label_dir.name or \"FaceShifter\" in label_dir.name or ignore in label_dir.name:\n",
    "            continue\n",
    "        label = label_dir.name\n",
    "        print(label)\n",
    "        dataset_dict[\"FaceForensics++\"][ff_dict[label]] = {}\n",
    "        dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"train\"] = {}\n",
    "        dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"test\"] = {}\n",
    "        dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"val\"] = {}\n",
    "\n",
    "        dataset_dict[\"FaceForensics++\"][\n",
    "            ff_dict[label]][\"train\"][compression_level] = {}\n",
    "        dataset_dict[\"FaceForensics++\"][\n",
    "            ff_dict[label]][\"test\"][compression_level] = {}\n",
    "        dataset_dict[\"FaceForensics++\"][\n",
    "            ff_dict[label]][\"val\"][compression_level] = {}\n",
    "\n",
    "        # Iterate over all videos\n",
    "        for video_path in os.scandir(\n",
    "                os.path.join(\n",
    "                    dataset_path,\n",
    "                    \"manipulated_sequences\",\n",
    "                    label,\n",
    "                    compression_level,\n",
    "                    \"rawframes\",\n",
    "                )):\n",
    "            if video_path.is_dir() and 'ipynb' not in video_path.name:\n",
    "                video_name = video_path.name\n",
    "                mode = video_to_mode[video_name]\n",
    "                frame_paths = [\n",
    "                    os.path.join(video_path, frame.name)\n",
    "                    for frame in os.scandir(video_path) \\\n",
    "                        if os.path.isfile(os.path.join(video_path, frame.name).replace('rawframes', 'landmarks').replace('png', 'npy')) and\\\n",
    "                        os.path.isfile(os.path.join(video_path, frame.name).replace('rawframes', 'retina').replace('png', 'npy'))\n",
    "                ]\n",
    "\n",
    "                dataset_dict[\"FaceForensics++\"][ff_dict[label]][mode][compression_level][\n",
    "                    video_name] = {\n",
    "                        \"label\": ff_dict[label],\n",
    "                        \"frames\": frame_paths\n",
    "                    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # for label, value in dataset_dict[\"FaceForensics++\"].items():\n",
    "    #     if label != \"FF-real\":\n",
    "    #         with open(os.path.join(output_file_path, f\"{label}.json\"),\n",
    "    #                     \"w\") as f:\n",
    "    #             data = {\n",
    "    #                 label: {\n",
    "    #                     \"FF-real\": dataset_dict[\"FaceForensics++\"][\"FF-real\"],\n",
    "    #                     label: value,\n",
    "    #                 }\n",
    "    #             }\n",
    "    #             json.dump(data, f)\n",
    "    #             print(f\"Finish writing {label}.json\")\n",
    "\n",
    "    with open(os.path.join(output_file_path, f\"FaceForensics++_without_{ignore}.json\"), \"w\") as f:\n",
    "        json.dump(dataset_dict, f)\n",
    "    print(f\"Finish writing FaceForensics++_without_{ignore}.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unseen manipulation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepfakes\n",
      "Finish writing FF-DF.json\n",
      "FaceSwap\n",
      "Finish writing FF-FS.json\n",
      "Face2Face\n",
      "Finish writing FF-F2F.json\n",
      "FaceShifter\n",
      "Finish writing FF-FH.json\n",
      "NeuralTextures\n",
      "Finish writing FF-NT.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_root_path = \"/mnt/sdc/maisie/\"\n",
    "compression_level = \"c23\"\n",
    "output_file_path  = \"/mnt/sdb/maisie/SelfBlendedImages/data\"\n",
    "\n",
    "ff_dict = {\n",
    "    \"Deepfakes\": \"FF-DF\",\n",
    "    \"Face2Face\": \"FF-F2F\",\n",
    "    \"FaceSwap\": \"FF-FS\",\n",
    "    \"Real\": \"FF-real\",\n",
    "    \"NeuralTextures\": \"FF-NT\",\n",
    "    \"FaceShifter\": \"FF-FH\",\n",
    "}\n",
    "\n",
    "# Load the JSON files for data split\n",
    "dataset_path = os.path.join(dataset_root_path, \"FaceForensics++\")\n",
    "\n",
    "# Load the JSON files for data split\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(\n",
    "                dataset_path,\n",
    "                \"train.json\",\n",
    "            )),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    train_json = json.load(f)\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(dataset_path,\"val.json\")),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    val_json = json.load(f)\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(dataset_path,\"test.json\")),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    test_json = json.load(f)\n",
    "video_to_mode = dict()\n",
    "for d1, d2 in train_json:\n",
    "    video_to_mode[d1] = \"train\"\n",
    "    video_to_mode[d2] = \"train\"\n",
    "    video_to_mode[d1 + \"_\" + d2] = \"train\"\n",
    "    video_to_mode[d2 + \"_\" + d1] = \"train\"\n",
    "for d1, d2 in val_json:\n",
    "    video_to_mode[d1] = 'train'\n",
    "    video_to_mode[d2] = 'train'\n",
    "    video_to_mode[d1+'_'+d2] = 'train'\n",
    "    video_to_mode[d2+'_'+d1] = 'train'\n",
    "for d1, d2 in test_json:\n",
    "    video_to_mode[d1] = 'test'\n",
    "    video_to_mode[d2] = 'test'\n",
    "    video_to_mode[d1+'_'+d2] = 'test'\n",
    "    video_to_mode[d2+'_'+d1] = 'test'\n",
    "\n",
    "\n",
    "\n",
    "labels = ['Deepfakes', 'FaceSwap', 'Face2Face', 'FaceShifter', 'NeuralTextures']\n",
    "# FaceForensics++ fake datasets\n",
    "for label in labels:\n",
    "    \n",
    "    print(label)\n",
    "    dataset_dict = {}\n",
    "\n",
    "    # FaceForensics++ real dataset\n",
    "    dataset_dict[\"FaceForensics++\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"] = {}\n",
    "\n",
    "    # Iterate over all compression levels: c23, c40, raw\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"train\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"test\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"val\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"train\"][compression_level] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"test\"][compression_level] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"val\"][compression_level] = {}\n",
    "\n",
    "    # Iterate over all videos\n",
    "    for video_path in os.scandir(\n",
    "            os.path.join(\n",
    "                dataset_path,\n",
    "                \"original_sequences\",\n",
    "                \"youtube\",\n",
    "                compression_level,\n",
    "                \"rawframes_test\",\n",
    "            )):\n",
    "        if video_path.is_dir() and 'ipynb' not in video_path.name:\n",
    "            video_name = video_path.name\n",
    "            mode = video_to_mode[video_name]\n",
    "\n",
    "            frame_paths = [\n",
    "                os.path.join(video_path, frame.name)\n",
    "                for frame in os.scandir(video_path) if '_' in frame.name\n",
    "            ]\n",
    "            dataset_dict[\"FaceForensics++\"][\"FF-real\"][mode][compression_level][video_name] = {\n",
    "                    \"label\": 'FF-real',\n",
    "                    \"frames\": frame_paths\n",
    "                }\n",
    "\n",
    "\n",
    "    dataset_dict[\"FaceForensics++\"][ff_dict[label]] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"train\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"test\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"val\"] = {}\n",
    "\n",
    "    dataset_dict[\"FaceForensics++\"][\n",
    "        ff_dict[label]][\"train\"][compression_level] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\n",
    "        ff_dict[label]][\"test\"][compression_level] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\n",
    "        ff_dict[label]][\"val\"][compression_level] = {}\n",
    "\n",
    "    # Iterate over all videos\n",
    "    for video_path in os.scandir(\n",
    "            os.path.join(\n",
    "                dataset_path,\n",
    "                \"manipulated_sequences\",\n",
    "                label,\n",
    "                compression_level,\n",
    "                \"rawframes_test\",\n",
    "            )):\n",
    "        \n",
    "        if video_path.is_dir() and 'ipynb' not in video_path.name:\n",
    "            video_name = video_path.name\n",
    "            mode = video_to_mode[video_name]\n",
    "            frame_paths = [\n",
    "                os.path.join(video_path, frame.name)\n",
    "                for frame in os.scandir(video_path) if '_' in frame.name\n",
    "            ]\n",
    "\n",
    "            dataset_dict[\"FaceForensics++\"][ff_dict[label]][mode][compression_level][\n",
    "                video_name] = {\n",
    "                    \"label\": ff_dict[label],\n",
    "                    \"frames\": frame_paths \n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for label, value in dataset_dict[\"FaceForensics++\"].items():\n",
    "        if label != \"FF-real\":\n",
    "            with open(os.path.join(output_file_path, f\"{label}.json\"),\n",
    "                        \"w\") as f:\n",
    "                data = {\n",
    "                    label: {\n",
    "                        \"FF-real\": dataset_dict[\"FaceForensics++\"][\"FF-real\"],\n",
    "                        label: value,\n",
    "                    }\n",
    "                }\n",
    "                json.dump(data, f)\n",
    "                print(f\"Finish writing {label}.json\")\n",
    "\n",
    "# with open(os.path.join(output_file_path, \"FF-FH.json\"), \"w\") as f:\n",
    "#     json.dump(dataset_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FF-NT.json\n",
      "Finish writing FF-F2F.json\n",
      "Finish writing FF-DF.json\n",
      "Finish writing FF-FS.json\n"
     ]
    }
   ],
   "source": [
    "dataset_root_path = \"/mnt/sdc/maisie/\"\n",
    "compression_level = \"c23\"\n",
    "output_file_path  = \"/mnt/sdb/maisie/SelfBlendedImages/data/FF++_trainwotest\"\n",
    "\n",
    "ff_dict = {\n",
    "    \"Deepfakes\": \"FF-DF\",\n",
    "    \"Face2Face\": \"FF-F2F\",\n",
    "    \"FaceSwap\": \"FF-FS\",\n",
    "    \"Real\": \"FF-real\",\n",
    "    \"NeuralTextures\": \"FF-NT\",\n",
    "    \"FaceShifter\": \"FF-FH\",\n",
    "}\n",
    "\n",
    "# Load the JSON files for data split\n",
    "dataset_path = os.path.join(dataset_root_path, \"FaceForensics++\")\n",
    "\n",
    "# Load the JSON files for data split\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(\n",
    "                dataset_path,\n",
    "                \"train.json\",\n",
    "            )),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    train_json = json.load(f)\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(dataset_path,\"val.json\")),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    val_json = json.load(f)\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(dataset_path,\"test.json\")),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    test_json = json.load(f)\n",
    "\n",
    "# Create a dictionary for searching the data split\n",
    "video_to_mode = dict()\n",
    "for d1, d2 in train_json:\n",
    "    video_to_mode[d1] = \"train\"\n",
    "    video_to_mode[d2] = \"train\"\n",
    "    video_to_mode[d1 + \"_\" + d2] = \"train\"\n",
    "    video_to_mode[d2 + \"_\" + d1] = \"train\"\n",
    "for d1, d2 in val_json:\n",
    "    video_to_mode[d1] = 'val'\n",
    "    video_to_mode[d2] = 'val'\n",
    "    video_to_mode[d1+'_'+d2] = 'val'\n",
    "    video_to_mode[d2+'_'+d1] = 'val'\n",
    "for d1, d2 in test_json:\n",
    "    video_to_mode[d1] = 'test'\n",
    "    video_to_mode[d2] = 'test'\n",
    "    video_to_mode[d1+'_'+d2] = 'test'\n",
    "    video_to_mode[d2+'_'+d1] = 'test'\n",
    "\n",
    "# Comment following to get whole FF++dataset to train\n",
    "# for d1, d2 in val_json:\n",
    "#     video_to_mode[d1] = 'val'\n",
    "#     video_to_mode[d2] = 'val'\n",
    "#     video_to_mode[d1+'_'+d2] = 'val'\n",
    "#     video_to_mode[d2+'_'+d1] = 'val'\n",
    "# for d1, d2 in test_json:\n",
    "#     video_to_mode[d1] = 'test'\n",
    "#     video_to_mode[d2] = 'test'\n",
    "#     video_to_mode[d1+'_'+d2] = 'test'\n",
    "#     video_to_mode[d2+'_'+d1] = 'test'\n",
    "\n",
    "dataset_dict = {}\n",
    "\n",
    "# FaceForensics++ real dataset\n",
    "label = \"Real\"\n",
    "dataset_dict[\"FaceForensics++\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"] = {}\n",
    "\n",
    "# Iterate over all compression levels: c23, c40, raw\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"train\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"test\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"val\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"train\"][compression_level] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"test\"][compression_level] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"val\"][compression_level] = {}\n",
    "\n",
    "# Iterate over all videos\n",
    "for video_path in os.scandir(\n",
    "        os.path.join(\n",
    "            dataset_path,\n",
    "            \"original_sequences\",\n",
    "            \"youtube\",\n",
    "            compression_level,\n",
    "            \"rawframes_test\",\n",
    "        )):\n",
    "    if video_path.is_dir() and 'ipynb' not in video_path.name:\n",
    "        video_name = video_path.name\n",
    "        mode = video_to_mode[video_name]\n",
    "        frame_paths = [\n",
    "            os.path.join(video_path, frame.name)\n",
    "            for frame in os.scandir(video_path)\n",
    "        ]\n",
    "\n",
    "        dataset_dict[\"FaceForensics++\"][\"FF-real\"][mode][compression_level][\n",
    "            video_name] = {\n",
    "                \"label\": ff_dict[label],\n",
    "                \"frames\": frame_paths\n",
    "            }\n",
    "\n",
    "\n",
    "# FaceForensics++ fake datasets\n",
    "for label_dir in os.scandir(os.path.join(dataset_path,\n",
    "                                         \"manipulated_sequences\")):\n",
    "    if \"youtube\" in label_dir.name or \"FaceShifter\" in label_dir.name:\n",
    "        continue\n",
    "    label = label_dir.name\n",
    "    print(label)\n",
    "    dataset_dict[\"FaceForensics++\"][ff_dict[label]] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"train\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"test\"] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"val\"] = {}\n",
    "\n",
    "    dataset_dict[\"FaceForensics++\"][\n",
    "        ff_dict[label]][\"train\"][compression_level] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\n",
    "        ff_dict[label]][\"test\"][compression_level] = {}\n",
    "    dataset_dict[\"FaceForensics++\"][\n",
    "        ff_dict[label]][\"val\"][compression_level] = {}\n",
    "\n",
    "    # Iterate over all videos\n",
    "    for video_path in os.scandir(\n",
    "            os.path.join(\n",
    "                dataset_path,\n",
    "                \"manipulated_sequences\",\n",
    "                label,\n",
    "                compression_level,\n",
    "                \"rawframes_test\",\n",
    "            )):\n",
    "        if video_path.is_dir() and 'ipynb' not in video_path.name:\n",
    "            video_name = video_path.name\n",
    "            mode = video_to_mode[video_name]\n",
    "            frame_paths = [\n",
    "                os.path.join(video_path, frame.name)\n",
    "                for frame in os.scandir(video_path)\n",
    "            ]\n",
    "\n",
    "            dataset_dict[\"FaceForensics++\"][ff_dict[label]][mode][compression_level][\n",
    "                video_name] = {\n",
    "                    \"label\": ff_dict[label],\n",
    "                    \"frames\": frame_paths\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for label, value in dataset_dict[\"FaceForensics++\"].items():\n",
    "    if label != \"FF-real\":\n",
    "        with open(os.path.join(output_file_path, f\"{label}.json\"),\n",
    "                    \"w\") as f:\n",
    "            data = {\n",
    "                label: {\n",
    "                    \"FF-real\": dataset_dict[\"FaceForensics++\"][\"FF-real\"],\n",
    "                    label: value,\n",
    "                }\n",
    "            }\n",
    "            json.dump(data, f)\n",
    "            print(f\"Finish writing {label}.json\")\n",
    "\n",
    "with open(os.path.join(output_file_path, \"FaceForensics++.json\"), \"w\") as f:\n",
    "    json.dump(dataset_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_CS_1.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_CS_2.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_CS_3.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_CS_4.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_CS_5.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_CC_1.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_CC_2.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_CC_3.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_CC_4.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_CC_5.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_BW_1.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_BW_2.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_BW_3.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_BW_4.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_BW_5.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_GNC_1.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_GNC_2.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_GNC_3.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_GNC_4.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_GNC_5.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_GB_1.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_GB_2.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_GB_3.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_GB_4.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_GB_5.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_JPEG_1.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_JPEG_2.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_JPEG_3.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_JPEG_4.json\n",
      "NeuralTextures\n",
      "Face2Face\n",
      "Deepfakes\n",
      "FaceSwap\n",
      "Finish writing FaceForensics++_JPEG_5.json\n"
     ]
    }
   ],
   "source": [
    "dataset_root_path = \"/mnt/sdc/maisie/\"\n",
    "compression_level = \"c23\"\n",
    "output_file_path  = \"/mnt/sdb/maisie/SelfBlendedImages/data/FF++_robustness\"\n",
    "\n",
    "ff_dict = {\n",
    "    \"Deepfakes\": \"FF-DF\",\n",
    "    \"Face2Face\": \"FF-F2F\",\n",
    "    \"FaceSwap\": \"FF-FS\",\n",
    "    \"Real\": \"FF-real\",\n",
    "    \"NeuralTextures\": \"FF-NT\",\n",
    "    \"FaceShifter\": \"FF-FH\",\n",
    "}\n",
    "\n",
    "# Load the JSON files for data split\n",
    "dataset_path = os.path.join(dataset_root_path, \"FaceForensics++\")\n",
    "\n",
    "# Load the JSON files for data split\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(\n",
    "                dataset_path,\n",
    "                \"train.json\",\n",
    "            )),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    train_json = json.load(f)\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(dataset_path,\"val.json\")),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    val_json = json.load(f)\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(dataset_path,\"test.json\")),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    test_json = json.load(f)\n",
    "\n",
    "# Create a dictionary for searching the data split\n",
    "video_to_mode = dict()\n",
    "for d1, d2 in train_json:\n",
    "    video_to_mode[d1] = \"train\"\n",
    "    video_to_mode[d2] = \"train\"\n",
    "    video_to_mode[d1 + \"_\" + d2] = \"train\"\n",
    "    video_to_mode[d2 + \"_\" + d1] = \"train\"\n",
    "for d1, d2 in val_json:\n",
    "    video_to_mode[d1] = 'val'\n",
    "    video_to_mode[d2] = 'val'\n",
    "    video_to_mode[d1+'_'+d2] = 'val'\n",
    "    video_to_mode[d2+'_'+d1] = 'val'\n",
    "for d1, d2 in test_json:\n",
    "    video_to_mode[d1] = 'test'\n",
    "    video_to_mode[d2] = 'test'\n",
    "    video_to_mode[d1+'_'+d2] = 'test'\n",
    "    video_to_mode[d2+'_'+d1] = 'test'\n",
    "\n",
    "# Iterate over all videos\n",
    "for type in ['CS', 'CC', 'BW', 'GNC', 'GB', 'JPEG']:\n",
    "    for level in range(1 , 6):\n",
    "\n",
    "        dataset_dict = {}\n",
    "\n",
    "        # FaceForensics++ real dataset\n",
    "        label = \"Real\"\n",
    "        dataset_dict[\"FaceForensics++\"] = {}\n",
    "        dataset_dict[\"FaceForensics++\"][\"FF-real\"] = {}\n",
    "\n",
    "        # Iterate over all compression levels: c23, c40, raw\n",
    "        dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"train\"] = {}\n",
    "        dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"test\"] = {}\n",
    "        dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"val\"] = {}\n",
    "        dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"train\"][compression_level] = {}\n",
    "        dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"test\"][compression_level] = {}\n",
    "        dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"val\"][compression_level] = {}\n",
    "\n",
    "\n",
    "        for video_path in os.scandir(\n",
    "                os.path.join(\n",
    "                    dataset_path,\n",
    "                    \"original_sequences\",\n",
    "                    \"youtube\",\n",
    "                    f\"{type}_{level}\",\n",
    "                    \"rawframes_test\",\n",
    "                )):\n",
    "            if video_path.is_dir() and 'ipynb' not in video_path.name:\n",
    "                video_name = video_path.name\n",
    "                mode = video_to_mode[video_name]\n",
    "                frame_paths = [\n",
    "                    os.path.join(video_path, frame.name)\n",
    "                    for frame in os.scandir(video_path)\n",
    "                ]\n",
    "\n",
    "                dataset_dict[\"FaceForensics++\"][\"FF-real\"][mode][compression_level][\n",
    "                    video_name] = {\n",
    "                        \"label\": ff_dict[label],\n",
    "                        \"frames\": frame_paths\n",
    "                    }\n",
    "\n",
    "\n",
    "        # FaceForensics++ fake datasets\n",
    "        for label_dir in os.scandir(os.path.join(dataset_path,\n",
    "                                                \"manipulated_sequences\")):\n",
    "            if \"youtube\" in label_dir.name or \"FaceShifter\" in label_dir.name:\n",
    "                continue\n",
    "            label = label_dir.name\n",
    "            print(label)\n",
    "            dataset_dict[\"FaceForensics++\"][ff_dict[label]] = {}\n",
    "            dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"train\"] = {}\n",
    "            dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"test\"] = {}\n",
    "            dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"val\"] = {}\n",
    "\n",
    "            dataset_dict[\"FaceForensics++\"][\n",
    "                ff_dict[label]][\"train\"][compression_level] = {}\n",
    "            dataset_dict[\"FaceForensics++\"][\n",
    "                ff_dict[label]][\"test\"][compression_level] = {}\n",
    "            dataset_dict[\"FaceForensics++\"][\n",
    "                ff_dict[label]][\"val\"][compression_level] = {}\n",
    "\n",
    "            # Iterate over all videos\n",
    "            for video_path in os.scandir(\n",
    "                    os.path.join(\n",
    "                        dataset_path,\n",
    "                        \"manipulated_sequences\",\n",
    "                        label,\n",
    "                        f\"{type}_{level}\",\n",
    "                        \"rawframes_test\",\n",
    "                    )):\n",
    "                if video_path.is_dir() and 'ipynb' not in video_path.name:\n",
    "                    video_name = video_path.name\n",
    "                    mode = video_to_mode[video_name]\n",
    "                    frame_paths = [\n",
    "                        os.path.join(video_path, frame.name)\n",
    "                        for frame in os.scandir(video_path)\n",
    "                    ]\n",
    "\n",
    "                    dataset_dict[\"FaceForensics++\"][ff_dict[label]][mode][compression_level][\n",
    "                        video_name] = {\n",
    "                            \"label\": ff_dict[label],\n",
    "                            \"frames\": frame_paths\n",
    "                        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # for label, value in dataset_dict[\"FaceForensics++\"].items():\n",
    "        #     if label != \"FF-real\":\n",
    "        #         with open(os.path.join(output_file_path, f\"{label}.json\"),\n",
    "        #                     \"w\") as f:\n",
    "        #             data = {\n",
    "        #                 label: {\n",
    "        #                     \"FF-real\": dataset_dict[\"FaceForensics++\"][\"FF-real\"],\n",
    "        #                     label: value,\n",
    "        #                 }\n",
    "        #             }\n",
    "        #             json.dump(data, f)\n",
    "        #             print(f\"Finish writing {label}.json\")\n",
    "        os.makedirs(output_file_path , exist_ok=True)\n",
    "        with open(os.path.join(output_file_path, f\"FaceForensics++_{type}_{level}.json\"), \"w\") as f:\n",
    "            json.dump(dataset_dict, f)\n",
    "            print(f\"Finish writing FaceForensics++_{type}_{level}.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root_path = '/mnt/sdb/maisie/Dataset_Deepfake/'\n",
    "dataset_path = os.path.join(dataset_root_path, \"DFDC/test\")\n",
    "output_file_path = \"/mnt/sdb/maisie/SelfBlendedImages/data\"\n",
    "\n",
    "dataset_dict = {}\n",
    "dataset_dict['DFDC'] = {\n",
    "    \"DFDC_Real\": {\n",
    "        \"train\": {},\n",
    "        \"test\": {},\n",
    "        \"val\": {}\n",
    "    },\n",
    "    \"DFDC_Fake\": {\n",
    "        \"train\": {},\n",
    "        \"test\": {},\n",
    "        \"val\": {}\n",
    "    },\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\n",
    "    os.path.join(dataset_path,\"labels.csv\"))\n",
    "labels = [\"DFDC_Real\", \"DFDC_Fake\"]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    vidname = row[\"filename\"].split(\".mp4\")[0]\n",
    "    label = labels[row[\"label\"]]\n",
    "    assert label in [\n",
    "        \"DFDC_Real\",\n",
    "        \"DFDC_Fake\",\n",
    "    ], \"Invalid label: {}\".format(label)\n",
    "    frame_paths = glob.glob(\n",
    "        os.path.join(dataset_path,\"rawframes\",vidname, \"*png\"))\n",
    "    # print(os.path.join(dataset_path,\"rawframes\",vidname, \"*png\"))\n",
    "    # frame_paths = [frames_path for frames_path in frame_paths if os.path.isfile(frames_path.replace('rawframes', 'retina').replace('png', 'npy'))]\n",
    "\n",
    "    dataset_dict[\"DFDC\"][label][\"test\"][vidname] = {\n",
    "        \"label\": label,\n",
    "        \"frames\": frame_paths,\n",
    "        }\n",
    "\n",
    "with open(os.path.join(output_file_path, \"DFDC.json\"), \"w\") as f:\n",
    "    json.dump(dataset_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CelebDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_root_path = '/mnt/sdc/maisie/'\n",
    "dataset_path = os.path.join(dataset_root_path, \"Celeb-DF-v2\")\n",
    "output_file_path = \"/mnt/sdb/maisie/SelfBlendedImages/data\"\n",
    "\n",
    "dataset_dict = {}\n",
    "dataset_dict[\"Celeb-DF-v2\"] = {}\n",
    "\n",
    "for folder in os.scandir(dataset_path):\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "    if folder.name in [\"Celeb-real\", \"YouTube-real\"]:\n",
    "        label = \"CelebDFv2_real\"\n",
    "    else:\n",
    "        label = \"CelebDFv2_fake\"\n",
    "    assert label in [\n",
    "        \"CelebDFv2_real\",\n",
    "        \"CelebDFv2_fake\",\n",
    "    ], \"Invalid label: {}\".format(label)\n",
    "    dataset_dict[\"Celeb-DF-v2\"][label] = {}\n",
    "    dataset_dict[\"Celeb-DF-v2\"][label][\"train\"] = {}\n",
    "    dataset_dict[\"Celeb-DF-v2\"][label][\"val\"] = {}\n",
    "    dataset_dict[\"Celeb-DF-v2\"][label][\"test\"] = {}\n",
    "\n",
    "\n",
    "with open(os.path.join(dataset_root_path, \"Celeb-DF-v2\",\"List_of_testing_videos.txt\"), \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "    if \"real\" in line:\n",
    "        label = \"CelebDFv2_real\"\n",
    "    elif \"synthesis\" in line:\n",
    "        label = \"CelebDFv2_fake\"\n",
    "    else:\n",
    "        raise ValueError(f\"wrong in processing vidname Celeb-DF-v2: {line}\")\n",
    "\n",
    "    vidname = line.split(\"\\n\")[0].split(\"/\")[-1].split(\".mp4\")[0]\n",
    "    frame_paths = glob.glob(\n",
    "        os.path.join(\n",
    "            dataset_root_path,\n",
    "            \"Celeb-DF-v2\",\n",
    "            line.split(\" \")[1].split(\"/\")[0],\n",
    "            \"rawframes\",\n",
    "            vidname,\n",
    "            \"*png\",\n",
    "        ))\n",
    "\n",
    "    # frame_paths = [\n",
    "    #     frame_paths[i] for i in range(len(frame_paths))\n",
    "    #     if os.path.isfile(frame_paths[i].replace(\n",
    "    #         \"/rawframes/\", \"/retina/\").replace(\".png\", \".npy\"))\n",
    "    # ]\n",
    "\n",
    "    dataset_dict[\"Celeb-DF-v2\"][label][\"test\"][vidname] = {\n",
    "        \"label\": label,\n",
    "        \"frames\": frame_paths,\n",
    "    }\n",
    "\n",
    "\n",
    "with open(os.path.join(output_file_path, \"Celeb-DF-v2.json\"), \"w\") as f:\n",
    "    json.dump(dataset_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faceshifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DirEntry '186'>\n",
      "<DirEntry '615'>\n",
      "<DirEntry '835'>\n",
      "<DirEntry '877'>\n",
      "<DirEntry '320'>\n",
      "<DirEntry '177'>\n",
      "<DirEntry '565'>\n",
      "<DirEntry '371'>\n",
      "<DirEntry '237'>\n",
      "<DirEntry '187'>\n",
      "<DirEntry '953'>\n",
      "<DirEntry '951'>\n",
      "<DirEntry '242'>\n",
      "<DirEntry '227'>\n",
      "<DirEntry '697'>\n",
      "<DirEntry '873'>\n",
      "<DirEntry '909'>\n",
      "<DirEntry '131'>\n",
      "<DirEntry '588'>\n",
      "<DirEntry '272'>\n",
      "<DirEntry '681'>\n",
      "<DirEntry '997'>\n",
      "<DirEntry '502'>\n",
      "<DirEntry '344'>\n",
      "<DirEntry '184'>\n",
      "<DirEntry '767'>\n",
      "<DirEntry '826'>\n",
      "<DirEntry '560'>\n",
      "<DirEntry '964'>\n",
      "<DirEntry '917'>\n",
      "<DirEntry '661'>\n",
      "<DirEntry '488'>\n",
      "<DirEntry '600'>\n",
      "<DirEntry '908'>\n",
      "<DirEntry '024'>\n",
      "<DirEntry '967'>\n",
      "<DirEntry '165'>\n",
      "<DirEntry '927'>\n",
      "<DirEntry '480'>\n",
      "<DirEntry '378'>\n",
      "<DirEntry '241'>\n",
      "<DirEntry '162'>\n",
      "<DirEntry '037'>\n",
      "<DirEntry '106'>\n",
      "<DirEntry '431'>\n",
      "<DirEntry '257'>\n",
      "<DirEntry '297'>\n",
      "<DirEntry '285'>\n",
      "<DirEntry '611'>\n",
      "<DirEntry '812'>\n",
      "<DirEntry '238'>\n",
      "<DirEntry '987'>\n",
      "<DirEntry '146'>\n",
      "<DirEntry '687'>\n",
      "<DirEntry '122'>\n",
      "<DirEntry '149'>\n",
      "<DirEntry '789'>\n",
      "<DirEntry '228'>\n",
      "<DirEntry '056'>\n",
      "<DirEntry '173'>\n",
      "<DirEntry '154'>\n",
      "<DirEntry '355'>\n",
      "<DirEntry '421'>\n",
      "<DirEntry '340'>\n",
      "<DirEntry '426'>\n",
      "<DirEntry '383'>\n",
      "<DirEntry '627'>\n",
      "<DirEntry '168'>\n",
      "<DirEntry '295'>\n",
      "<DirEntry '980'>\n",
      "<DirEntry '570'>\n",
      "<DirEntry '972'>\n",
      "<DirEntry '054'>\n",
      "<DirEntry '810'>\n",
      "<DirEntry '988'>\n",
      "<DirEntry '389'>\n",
      "<DirEntry '239'>\n",
      "<DirEntry '757'>\n",
      "<DirEntry '839'>\n",
      "<DirEntry '563'>\n",
      "<DirEntry '171'>\n",
      "<DirEntry '283'>\n",
      "<DirEntry '256'>\n",
      "<DirEntry '304'>\n",
      "<DirEntry '046'>\n",
      "<DirEntry '216'>\n",
      "<DirEntry '005'>\n",
      "<DirEntry '126'>\n",
      "<DirEntry '646'>\n",
      "<DirEntry '335'>\n",
      "<DirEntry '753'>\n",
      "<DirEntry '506'>\n",
      "<DirEntry '359'>\n",
      "<DirEntry '721'>\n",
      "<DirEntry '998'>\n",
      "<DirEntry '829'>\n",
      "<DirEntry '605'>\n",
      "<DirEntry '236'>\n",
      "<DirEntry '667'>\n",
      "<DirEntry '501'>\n",
      "<DirEntry '043'>\n",
      "<DirEntry '594'>\n",
      "<DirEntry '781'>\n",
      "<DirEntry '234'>\n",
      "<DirEntry '221'>\n",
      "<DirEntry '666'>\n",
      "<DirEntry '976'>\n",
      "<DirEntry '066'>\n",
      "<DirEntry '622'>\n",
      "<DirEntry '941'>\n",
      "<DirEntry '743'>\n",
      "<DirEntry '437'>\n",
      "<DirEntry '328'>\n",
      "<DirEntry '791'>\n",
      "<DirEntry '883'>\n",
      "<DirEntry '416'>\n",
      "<DirEntry '995'>\n",
      "<DirEntry '983'>\n",
      "<DirEntry '051'>\n",
      "<DirEntry '469'>\n",
      "<DirEntry '525'>\n",
      "<DirEntry '580'>\n",
      "<DirEntry '943'>\n",
      "<DirEntry '356'>\n",
      "<DirEntry '261'>\n",
      "<DirEntry '178'>\n",
      "<DirEntry '167'>\n",
      "<DirEntry '731'>\n",
      "<DirEntry '053'>\n",
      "<DirEntry '694'>\n",
      "<DirEntry '740'>\n",
      "<DirEntry '901'>\n",
      "<DirEntry '720'>\n",
      "<DirEntry '894'>\n",
      "<DirEntry '855'>\n",
      "<DirEntry '109'>\n",
      "<DirEntry '008'>\n",
      "<DirEntry '719'>\n",
      "<DirEntry '978'>\n",
      "<DirEntry '785'>\n",
      "<DirEntry '843'>\n",
      "<DirEntry '210'>\n",
      "<DirEntry '394'>\n",
      "<DirEntry '526'>\n",
      "<DirEntry '683'>\n",
      "<DirEntry '515'>\n",
      "<DirEntry '624'>\n",
      "<DirEntry '420'>\n",
      "<DirEntry '879'>\n",
      "<DirEntry '465'>\n",
      "<DirEntry '747'>\n",
      "<DirEntry '673'>\n",
      "<DirEntry '840'>\n",
      "<DirEntry '311'>\n",
      "<DirEntry '595'>\n",
      "<DirEntry '090'>\n",
      "<DirEntry '543'>\n",
      "<DirEntry '693'>\n",
      "<DirEntry '145'>\n",
      "<DirEntry '208'>\n",
      "<DirEntry '955'>\n",
      "<DirEntry '240'>\n",
      "<DirEntry '599'>\n",
      "<DirEntry '643'>\n",
      "<DirEntry '478'>\n",
      "<DirEntry '601'>\n",
      "<DirEntry '245'>\n",
      "<DirEntry '350'>\n",
      "<DirEntry '761'>\n",
      "<DirEntry '704'>\n",
      "<DirEntry '706'>\n",
      "<DirEntry '858'>\n",
      "<DirEntry '253'>\n",
      "<DirEntry '886'>\n",
      "<DirEntry '618'>\n",
      "<DirEntry '317'>\n",
      "<DirEntry '689'>\n",
      "<DirEntry '656'>\n",
      "<DirEntry '822'>\n",
      "<DirEntry '907'>\n",
      "<DirEntry '809'>\n",
      "<DirEntry '979'>\n",
      "<DirEntry '482'>\n",
      "<DirEntry '737'>\n",
      "<DirEntry '973'>\n",
      "<DirEntry '919'>\n",
      "<DirEntry '726'>\n",
      "<DirEntry '934'>\n",
      "<DirEntry '797'>\n",
      "<DirEntry '111'>\n",
      "<DirEntry '157'>\n",
      "<DirEntry '940'>\n",
      "<DirEntry '891'>\n",
      "<DirEntry '007'>\n",
      "<DirEntry '583'>\n",
      "<DirEntry '463'>\n",
      "<DirEntry '760'>\n",
      "<DirEntry '068'>\n",
      "<DirEntry '079'>\n",
      "<DirEntry '223'>\n",
      "<DirEntry '281'>\n",
      "<DirEntry '275'>\n",
      "<DirEntry '736'>\n",
      "<DirEntry '460'>\n",
      "<DirEntry '621'>\n",
      "<DirEntry '192'>\n",
      "<DirEntry '040'>\n",
      "<DirEntry '462'>\n",
      "<DirEntry '430'>\n",
      "<DirEntry '330'>\n",
      "<DirEntry '354'>\n",
      "<DirEntry '333'>\n",
      "<DirEntry '148'>\n",
      "<DirEntry '816'>\n",
      "<DirEntry '407'>\n",
      "<DirEntry '684'>\n",
      "<DirEntry '081'>\n",
      "<DirEntry '688'>\n",
      "<DirEntry '634'>\n",
      "<DirEntry '677'>\n",
      "<DirEntry '377'>\n",
      "<DirEntry '442'>\n",
      "<DirEntry '433'>\n",
      "<DirEntry '614'>\n",
      "<DirEntry '254'>\n",
      "<DirEntry '141'>\n",
      "<DirEntry '668'>\n",
      "<DirEntry '073'>\n",
      "<DirEntry '871'>\n",
      "<DirEntry '452'>\n",
      "<DirEntry '288'>\n",
      "<DirEntry '268'>\n",
      "<DirEntry '226'>\n",
      "<DirEntry '590'>\n",
      "<DirEntry '386'>\n",
      "<DirEntry '057'>\n",
      "<DirEntry '331'>\n",
      "<DirEntry '287'>\n",
      "<DirEntry '182'>\n",
      "<DirEntry '852'>\n",
      "<DirEntry '655'>\n",
      "<DirEntry '916'>\n",
      "<DirEntry '125'>\n",
      "<DirEntry '597'>\n",
      "<DirEntry '670'>\n",
      "<DirEntry '047'>\n",
      "<DirEntry '446'>\n",
      "<DirEntry '813'>\n",
      "<DirEntry '298'>\n",
      "<DirEntry '273'>\n",
      "<DirEntry '977'>\n",
      "<DirEntry '799'>\n",
      "<DirEntry '651'>\n",
      "<DirEntry '540'>\n",
      "<DirEntry '395'>\n",
      "<DirEntry '734'>\n",
      "<DirEntry '009'>\n",
      "<DirEntry '617'>\n",
      "<DirEntry '610'>\n",
      "<DirEntry '118'>\n",
      "<DirEntry '374'>\n",
      "<DirEntry '780'>\n",
      "<DirEntry '986'>\n",
      "<DirEntry '267'>\n",
      "<DirEntry '464'>\n",
      "<DirEntry '074'>\n",
      "<DirEntry '017'>\n",
      "<DirEntry '918'>\n",
      "<DirEntry '754'>\n",
      "<DirEntry '522'>\n",
      "<DirEntry '034'>\n",
      "<DirEntry '351'>\n",
      "<DirEntry '003'>\n",
      "<DirEntry '181'>\n",
      "<DirEntry '454'>\n",
      "<DirEntry '613'>\n",
      "<DirEntry '483'>\n",
      "<DirEntry '484'>\n",
      "<DirEntry '492'>\n",
      "<DirEntry '458'>\n",
      "<DirEntry '376'>\n",
      "<DirEntry '808'>\n",
      "<DirEntry '382'>\n",
      "<DirEntry '513'>\n",
      "<DirEntry '496'>\n",
      "<DirEntry '532'>\n",
      "<DirEntry '336'>\n",
      "<DirEntry '630'>\n",
      "<DirEntry '685'>\n",
      "<DirEntry '664'>\n",
      "<DirEntry '116'>\n",
      "<DirEntry '015'>\n",
      "<DirEntry '222'>\n",
      "<DirEntry '652'>\n",
      "<DirEntry '898'>\n",
      "<DirEntry '968'>\n",
      "<DirEntry '890'>\n",
      "<DirEntry '415'>\n",
      "<DirEntry '584'>\n",
      "<DirEntry '010'>\n",
      "<DirEntry '405'>\n",
      "<DirEntry '572'>\n",
      "<DirEntry '961'>\n",
      "<DirEntry '867'>\n",
      "<DirEntry '207'>\n",
      "<DirEntry '302'>\n",
      "<DirEntry '447'>\n",
      "<DirEntry '423'>\n",
      "<DirEntry '474'>\n",
      "<DirEntry '029'>\n",
      "<DirEntry '076'>\n",
      "<DirEntry '577'>\n",
      "<DirEntry '132'>\n",
      "<DirEntry '039'>\n",
      "<DirEntry '561'>\n",
      "<DirEntry '984'>\n",
      "<DirEntry '539'>\n",
      "<DirEntry '735'>\n",
      "<DirEntry '370'>\n",
      "<DirEntry '921'>\n",
      "<DirEntry '535'>\n",
      "<DirEntry '582'>\n",
      "<DirEntry '158'>\n",
      "<DirEntry '391'>\n",
      "<DirEntry '853'>\n",
      "<DirEntry '648'>\n",
      "<DirEntry '692'>\n",
      "<DirEntry '825'>\n",
      "<DirEntry '768'>\n",
      "<DirEntry '140'>\n",
      "<DirEntry '263'>\n",
      "<DirEntry '290'>\n",
      "<DirEntry '347'>\n",
      "<DirEntry '249'>\n",
      "<DirEntry '201'>\n",
      "<DirEntry '095'>\n",
      "<DirEntry '657'>\n",
      "<DirEntry '663'>\n",
      "<DirEntry '860'>\n",
      "<DirEntry '419'>\n",
      "<DirEntry '271'>\n",
      "<DirEntry '329'>\n",
      "<DirEntry '625'>\n",
      "<DirEntry '795'>\n",
      "<DirEntry '727'>\n",
      "<DirEntry '094'>\n",
      "<DirEntry '019'>\n",
      "<DirEntry '211'>\n",
      "<DirEntry '400'>\n",
      "<DirEntry '220'>\n",
      "<DirEntry '505'>\n",
      "<DirEntry '866'>\n",
      "<DirEntry '665'>\n",
      "<DirEntry '793'>\n",
      "<DirEntry '936'>\n",
      "<DirEntry '231'>\n",
      "<DirEntry '857'>\n",
      "<DirEntry '439'>\n",
      "<DirEntry '144'>\n",
      "<DirEntry '990'>\n",
      "<DirEntry '698'>\n",
      "<DirEntry '523'>\n",
      "<DirEntry '380'>\n",
      "<DirEntry '705'>\n",
      "<DirEntry '653'>\n",
      "<DirEntry '729'>\n",
      "<DirEntry '497'>\n",
      "<DirEntry '289'>\n",
      "<DirEntry '807'>\n",
      "<DirEntry '717'>\n",
      "<DirEntry '114'>\n",
      "<DirEntry '206'>\n",
      "<DirEntry '472'>\n",
      "<DirEntry '159'>\n",
      "<DirEntry '935'>\n",
      "<DirEntry '937'>\n",
      "<DirEntry '796'>\n",
      "<DirEntry '310'>\n",
      "<DirEntry '755'>\n",
      "<DirEntry '982'>\n",
      "<DirEntry '279'>\n",
      "<DirEntry '495'>\n",
      "<DirEntry '521'>\n",
      "<DirEntry '417'>\n",
      "<DirEntry '548'>\n",
      "<DirEntry '485'>\n",
      "<DirEntry '000'>\n",
      "<DirEntry '406'>\n",
      "<DirEntry '479'>\n",
      "<DirEntry '265'>\n",
      "<DirEntry '214'>\n",
      "<DirEntry '348'>\n",
      "<DirEntry '633'>\n",
      "<DirEntry '718'>\n",
      "<DirEntry '324'>\n",
      "<DirEntry '756'>\n",
      "<DirEntry '315'>\n",
      "<DirEntry '325'>\n",
      "<DirEntry '626'>\n",
      "<DirEntry '507'>\n",
      "<DirEntry '547'>\n",
      "<DirEntry '888'>\n",
      "<DirEntry '550'>\n",
      "<DirEntry '323'>\n",
      "<DirEntry '586'>\n",
      "<DirEntry '644'>\n",
      "<DirEntry '128'>\n",
      "<DirEntry '491'>\n",
      "<DirEntry '593'>\n",
      "<DirEntry '088'>\n",
      "<DirEntry '619'>\n",
      "<DirEntry '923'>\n",
      "<DirEntry '014'>\n",
      "<DirEntry '471'>\n",
      "<DirEntry '509'>\n",
      "<DirEntry '172'>\n",
      "<DirEntry '262'>\n",
      "<DirEntry '742'>\n",
      "<DirEntry '710'>\n",
      "<DirEntry '589'>\n",
      "<DirEntry '366'>\n",
      "<DirEntry '456'>\n",
      "<DirEntry '893'>\n",
      "<DirEntry '555'>\n",
      "<DirEntry '198'>\n",
      "<DirEntry '642'>\n",
      "<DirEntry '078'>\n",
      "<DirEntry '102'>\n",
      "<DirEntry '587'>\n",
      "<DirEntry '641'>\n",
      "<DirEntry '746'>\n",
      "<DirEntry '802'>\n",
      "<DirEntry '352'>\n",
      "<DirEntry '738'>\n",
      "<DirEntry '884'>\n",
      "<DirEntry '151'>\n",
      "<DirEntry '367'>\n",
      "<DirEntry '769'>\n",
      "<DirEntry '814'>\n",
      "<DirEntry '863'>\n",
      "<DirEntry '999'>\n",
      "<DirEntry '188'>\n",
      "<DirEntry '092'>\n",
      "<DirEntry '486'>\n",
      "<DirEntry '635'>\n",
      "<DirEntry '164'>\n",
      "<DirEntry '638'>\n",
      "<DirEntry '023'>\n",
      "<DirEntry '574'>\n",
      "<DirEntry '503'>\n",
      "<DirEntry '179'>\n",
      "<DirEntry '432'>\n",
      "<DirEntry '133'>\n",
      "<DirEntry '545'>\n",
      "<DirEntry '230'>\n",
      "<DirEntry '119'>\n",
      "<DirEntry '966'>\n",
      "<DirEntry '218'>\n",
      "<DirEntry '466'>\n",
      "<DirEntry '971'>\n",
      "<DirEntry '922'>\n",
      "<DirEntry '278'>\n",
      "<DirEntry '530'>\n",
      "<DirEntry '229'>\n",
      "<DirEntry '185'>\n",
      "<DirEntry '905'>\n",
      "<DirEntry '477'>\n",
      "<DirEntry '036'>\n",
      "<DirEntry '750'>\n",
      "<DirEntry '952'>\n",
      "<DirEntry '803'>\n",
      "<DirEntry '313'>\n",
      "<DirEntry '531'>\n",
      "<DirEntry '832'>\n",
      "<DirEntry '674'>\n",
      "<DirEntry '938'>\n",
      "<DirEntry '393'>\n",
      "<DirEntry '994'>\n",
      "<DirEntry '568'>\n",
      "<DirEntry '339'>\n",
      "<DirEntry '299'>\n",
      "<DirEntry '956'>\n",
      "<DirEntry '409'>\n",
      "<DirEntry '538'>\n",
      "<DirEntry '752'>\n",
      "<DirEntry '091'>\n",
      "<DirEntry '448'>\n",
      "<DirEntry '363'>\n",
      "<DirEntry '631'>\n",
      "<DirEntry '647'>\n",
      "<DirEntry '514'>\n",
      "<DirEntry '818'>\n",
      "<DirEntry '763'>\n",
      "<DirEntry '695'>\n",
      "<DirEntry '493'>\n",
      "<DirEntry '875'>\n",
      "<DirEntry '847'>\n",
      "<DirEntry '512'>\n",
      "<DirEntry '682'>\n",
      "<DirEntry '163'>\n",
      "<DirEntry '960'>\n",
      "<DirEntry '255'>\n",
      "<DirEntry '696'>\n",
      "<DirEntry '553'>\n",
      "<DirEntry '306'>\n",
      "<DirEntry '358'>\n",
      "<DirEntry '449'>\n",
      "<DirEntry '166'>\n",
      "<DirEntry '817'>\n",
      "<DirEntry '970'>\n",
      "<DirEntry '679'>\n",
      "<DirEntry '429'>\n",
      "<DirEntry '105'>\n",
      "<DirEntry '099'>\n",
      "<DirEntry '085'>\n",
      "<DirEntry '307'>\n",
      "<DirEntry '786'>\n",
      "<DirEntry '345'>\n",
      "<DirEntry '963'>\n",
      "<DirEntry '120'>\n",
      "<DirEntry '250'>\n",
      "<DirEntry '904'>\n",
      "<DirEntry '820'>\n",
      "<DirEntry '269'>\n",
      "<DirEntry '519'>\n",
      "<DirEntry '992'>\n",
      "<DirEntry '176'>\n",
      "<DirEntry '930'>\n",
      "<DirEntry '788'>\n",
      "<DirEntry '745'>\n",
      "<DirEntry '058'>\n",
      "<DirEntry '143'>\n",
      "<DirEntry '129'>\n",
      "<DirEntry '831'>\n",
      "<DirEntry '117'>\n",
      "<DirEntry '215'>\n",
      "<DirEntry '204'>\n",
      "<DirEntry '096'>\n",
      "<DirEntry '933'>\n",
      "<DirEntry '851'>\n",
      "<DirEntry '042'>\n",
      "<DirEntry '882'>\n",
      "<DirEntry '845'>\n",
      "<DirEntry '217'>\n",
      "<DirEntry '541'>\n",
      "<DirEntry '069'>\n",
      "<DirEntry '438'>\n",
      "<DirEntry '390'>\n",
      "<DirEntry '529'>\n",
      "<DirEntry '854'>\n",
      "<DirEntry '790'>\n",
      "<DirEntry '714'>\n",
      "<DirEntry '991'>\n",
      "<DirEntry '098'>\n",
      "<DirEntry '841'>\n",
      "<DirEntry '410'>\n",
      "<DirEntry '758'>\n",
      "<DirEntry '200'>\n",
      "<DirEntry '724'>\n",
      "<DirEntry '709'>\n",
      "<DirEntry '199'>\n",
      "<DirEntry '041'>\n",
      "<DirEntry '864'>\n",
      "<DirEntry '636'>\n",
      "<DirEntry '678'>\n",
      "<DirEntry '914'>\n",
      "<DirEntry '778'>\n",
      "<DirEntry '603'>\n",
      "<DirEntry '309'>\n",
      "<DirEntry '451'>\n",
      "<DirEntry '993'>\n",
      "<DirEntry '277'>\n",
      "<DirEntry '876'>\n",
      "<DirEntry '920'>\n",
      "<DirEntry '557'>\n",
      "<DirEntry '834'>\n",
      "<DirEntry '473'>\n",
      "<DirEntry '604'>\n",
      "<DirEntry '115'>\n",
      "<DirEntry '134'>\n",
      "<DirEntry '022'>\n",
      "<DirEntry '958'>\n",
      "<DirEntry '414'>\n",
      "<DirEntry '123'>\n",
      "<DirEntry '202'>\n",
      "<DirEntry '312'>\n",
      "<DirEntry '945'>\n",
      "<DirEntry '427'>\n",
      "<DirEntry '197'>\n",
      "<DirEntry '194'>\n",
      "<DirEntry '616'>\n",
      "<DirEntry '243'>\n",
      "<DirEntry '028'>\n",
      "<DirEntry '804'>\n",
      "<DirEntry '110'>\n",
      "<DirEntry '926'>\n",
      "<DirEntry '001'>\n",
      "<DirEntry '575'>\n",
      "<DirEntry '413'>\n",
      "<DirEntry '608'>\n",
      "<DirEntry '537'>\n",
      "<DirEntry '581'>\n",
      "<DirEntry '387'>\n",
      "<DirEntry '411'>\n",
      "<DirEntry '153'>\n",
      "<DirEntry '264'>\n",
      "<DirEntry '771'>\n",
      "<DirEntry '975'>\n",
      "<DirEntry '872'>\n",
      "<DirEntry '708'>\n",
      "<DirEntry '620'>\n",
      "<DirEntry '252'>\n",
      "<DirEntry '773'>\n",
      "<DirEntry '623'>\n",
      "<DirEntry '516'>\n",
      "<DirEntry '775'>\n",
      "<DirEntry '027'>\n",
      "<DirEntry '018'>\n",
      "<DirEntry '759'>\n",
      "<DirEntry '607'>\n",
      "<DirEntry '183'>\n",
      "<DirEntry '130'>\n",
      "<DirEntry '062'>\n",
      "<DirEntry '444'>\n",
      "<DirEntry '026'>\n",
      "<DirEntry '527'>\n",
      "<DirEntry '715'>\n",
      "<DirEntry '558'>\n",
      "<DirEntry '830'>\n",
      "<DirEntry '161'>\n",
      "<DirEntry '284'>\n",
      "<DirEntry '762'>\n",
      "<DirEntry '842'>\n",
      "<DirEntry '711'>\n",
      "<DirEntry '457'>\n",
      "<DirEntry '248'>\n",
      "<DirEntry '063'>\n",
      "<DirEntry '950'>\n",
      "<DirEntry '155'>\n",
      "<DirEntry '680'>\n",
      "<DirEntry '915'>\n",
      "<DirEntry '011'>\n",
      "<DirEntry '205'>\n",
      "<DirEntry '932'>\n",
      "<DirEntry '556'>\n",
      "<DirEntry '800'>\n",
      "<DirEntry '061'>\n",
      "<DirEntry '035'>\n",
      "<DirEntry '676'>\n",
      "<DirEntry '878'>\n",
      "<DirEntry '765'>\n",
      "<DirEntry '517'>\n",
      "<DirEntry '549'>\n",
      "<DirEntry '362'>\n",
      "<DirEntry '499'>\n",
      "<DirEntry '733'>\n",
      "<DirEntry '974'>\n",
      "<DirEntry '020'>\n",
      "<DirEntry '533'>\n",
      "<DirEntry '093'>\n",
      "<DirEntry '384'>\n",
      "<DirEntry '373'>\n",
      "<DirEntry '730'>\n",
      "<DirEntry '108'>\n",
      "<DirEntry '212'>\n",
      "<DirEntry '300'>\n",
      "<DirEntry '101'>\n",
      "<DirEntry '518'>\n",
      "<DirEntry '846'>\n",
      "<DirEntry '235'>\n",
      "<DirEntry '232'>\n",
      "<DirEntry '103'>\n",
      "<DirEntry '060'>\n",
      "<DirEntry '662'>\n",
      "<DirEntry '899'>\n",
      "<DirEntry '868'>\n",
      "<DirEntry '985'>\n",
      "<DirEntry '784'>\n",
      "<DirEntry '741'>\n",
      "<DirEntry '049'>\n",
      "<DirEntry '906'>\n",
      "<DirEntry '112'>\n",
      "<DirEntry '455'>\n",
      "<DirEntry '897'>\n",
      "<DirEntry '787'>\n",
      "<DirEntry '779'>\n",
      "<DirEntry '052'>\n",
      "<DirEntry '067'>\n",
      "<DirEntry '602'>\n",
      "<DirEntry '828'>\n",
      "<DirEntry '224'>\n",
      "<DirEntry '070'>\n",
      "<DirEntry '083'>\n",
      "<DirEntry '441'>\n",
      "<DirEntry '811'>\n",
      "<DirEntry '422'>\n",
      "<DirEntry '196'>\n",
      "<DirEntry '911'>\n",
      "<DirEntry '912'>\n",
      "<DirEntry '524'>\n",
      "<DirEntry '412'>\n",
      "<DirEntry '722'>\n",
      "<DirEntry '739'>\n",
      "<DirEntry '435'>\n",
      "<DirEntry '632'>\n",
      "<DirEntry '445'>\n",
      "<DirEntry '372'>\n",
      "<DirEntry '399'>\n",
      "<DirEntry '576'>\n",
      "<DirEntry '113'>\n",
      "<DirEntry '640'>\n",
      "<DirEntry '544'>\n",
      "<DirEntry '280'>\n",
      "<DirEntry '213'>\n",
      "<DirEntry '467'>\n",
      "<DirEntry '082'>\n",
      "<DirEntry '259'>\n",
      "<DirEntry '536'>\n",
      "<DirEntry '364'>\n",
      "<DirEntry '270'>\n",
      "<DirEntry '004'>\n",
      "<DirEntry '033'>\n",
      "<DirEntry '321'>\n",
      "<DirEntry '783'>\n",
      "<DirEntry '397'>\n",
      "<DirEntry '939'>\n",
      "<DirEntry '428'>\n",
      "<DirEntry '021'>\n",
      "<DirEntry '534'>\n",
      "<DirEntry '086'>\n",
      "<DirEntry '819'>\n",
      "<DirEntry '551'>\n",
      "<DirEntry '824'>\n",
      "<DirEntry '798'>\n",
      "<DirEntry '337'>\n",
      "<DirEntry '244'>\n",
      "<DirEntry '528'>\n",
      "<DirEntry '713'>\n",
      "<DirEntry '169'>\n",
      "<DirEntry '006'>\n",
      "<DirEntry '827'>\n",
      "<DirEntry '669'>\n",
      "<DirEntry '931'>\n",
      "<DirEntry '838'>\n",
      "<DirEntry '579'>\n",
      "<DirEntry '291'>\n",
      "<DirEntry '896'>\n",
      "<DirEntry '481'>\n",
      "<DirEntry '606'>\n",
      "<DirEntry '434'>\n",
      "<DirEntry '314'>\n",
      "<DirEntry '564'>\n",
      "<DirEntry '332'>\n",
      "<DirEntry '942'>\n",
      "<DirEntry '174'>\n",
      "<DirEntry '490'>\n",
      "<DirEntry '461'>\n",
      "<DirEntry '305'>\n",
      "<DirEntry '571'>\n",
      "<DirEntry '500'>\n",
      "<DirEntry '360'>\n",
      "<DirEntry '369'>\n",
      "<DirEntry '645'>\n",
      "<DirEntry '996'>\n",
      "<DirEntry '453'>\n",
      "<DirEntry '365'>\n",
      "<DirEntry '690'>\n",
      "<DirEntry '732'>\n",
      "<DirEntry '654'>\n",
      "<DirEntry '637'>\n",
      "<DirEntry '567'>\n",
      "<DirEntry '650'>\n",
      "<DirEntry '459'>\n",
      "<DirEntry '772'>\n",
      "<DirEntry '794'>\n",
      "<DirEntry '889'>\n",
      "<DirEntry '396'>\n",
      "<DirEntry '025'>\n",
      "<DirEntry '327'>\n",
      "<DirEntry '375'>\n",
      "<DirEntry '703'>\n",
      "<DirEntry '801'>\n",
      "<DirEntry '639'>\n",
      "<DirEntry '821'>\n",
      "<DirEntry '725'>\n",
      "<DirEntry '774'>\n",
      "<DirEntry '142'>\n",
      "<DirEntry '338'>\n",
      "<DirEntry '139'>\n",
      "<DirEntry '322'>\n",
      "<DirEntry '072'>\n",
      "<DirEntry '368'>\n",
      "<DirEntry '075'>\n",
      "<DirEntry '612'>\n",
      "<DirEntry '957'>\n",
      "<DirEntry '751'>\n",
      "<DirEntry '031'>\n",
      "<DirEntry '276'>\n",
      "<DirEntry '700'>\n",
      "<DirEntry '489'>\n",
      "<DirEntry '097'>\n",
      "<DirEntry '059'>\n",
      "<DirEntry '189'>\n",
      "<DirEntry '225'>\n",
      "<DirEntry '209'>\n",
      "<DirEntry '862'>\n",
      "<DirEntry '401'>\n",
      "<DirEntry '511'>\n",
      "<DirEntry '030'>\n",
      "<DirEntry '147'>\n",
      "<DirEntry '055'>\n",
      "<DirEntry '823'>\n",
      "<DirEntry '282'>\n",
      "<DirEntry '559'>\n",
      "<DirEntry '885'>\n",
      "<DirEntry '944'>\n",
      "<DirEntry '404'>\n",
      "<DirEntry '859'>\n",
      "<DirEntry '949'>\n",
      "<DirEntry '104'>\n",
      "<DirEntry '591'>\n",
      "<DirEntry '100'>\n",
      "<DirEntry '301'>\n",
      "<DirEntry '504'>\n",
      "<DirEntry '418'>\n",
      "<DirEntry '319'>\n",
      "<DirEntry '247'>\n",
      "<DirEntry '629'>\n",
      "<DirEntry '343'>\n",
      "<DirEntry '954'>\n",
      "<DirEntry '776'>\n",
      "<DirEntry '691'>\n",
      "<DirEntry '219'>\n",
      "<DirEntry '044'>\n",
      "<DirEntry '425'>\n",
      "<DirEntry '160'>\n",
      "<DirEntry '546'>\n",
      "<DirEntry '924'>\n",
      "<DirEntry '573'>\n",
      "<DirEntry '190'>\n",
      "<DirEntry '744'>\n",
      "<DirEntry '468'>\n",
      "<DirEntry '598'>\n",
      "<DirEntry '258'>\n",
      "<DirEntry '833'>\n",
      "<DirEntry '585'>\n",
      "<DirEntry '659'>\n",
      "<DirEntry '424'>\n",
      "<DirEntry '749'>\n",
      "<DirEntry '443'>\n",
      "<DirEntry '398'>\n",
      "<DirEntry '844'>\n",
      "<DirEntry '002'>\n",
      "<DirEntry '880'>\n",
      "<DirEntry '408'>\n",
      "<DirEntry '913'>\n",
      "<DirEntry '569'>\n",
      "<DirEntry '138'>\n",
      "<DirEntry '385'>\n",
      "<DirEntry '038'>\n",
      "<DirEntry '233'>\n",
      "<DirEntry '403'>\n",
      "<DirEntry '175'>\n",
      "<DirEntry '357'>\n",
      "<DirEntry '260'>\n",
      "<DirEntry '777'>\n",
      "<DirEntry '837'>\n",
      "<DirEntry '900'>\n",
      "<DirEntry '578'>\n",
      "<DirEntry '520'>\n",
      "<DirEntry '346'>\n",
      "<DirEntry '436'>\n",
      "<DirEntry '566'>\n",
      "<DirEntry '946'>\n",
      "<DirEntry '658'>\n",
      "<DirEntry '450'>\n",
      "<DirEntry '274'>\n",
      "<DirEntry '959'>\n",
      "<DirEntry '728'>\n",
      "<DirEntry '050'>\n",
      "<DirEntry '805'>\n",
      "<DirEntry '895'>\n",
      "<DirEntry '766'>\n",
      "<DirEntry '107'>\n",
      "<DirEntry '379'>\n",
      "<DirEntry '962'>\n",
      "<DirEntry '929'>\n",
      "<DirEntry '782'>\n",
      "<DirEntry '361'>\n",
      "<DirEntry '887'>\n",
      "<DirEntry '609'>\n",
      "<DirEntry '552'>\n",
      "<DirEntry '850'>\n",
      "<DirEntry '881'>\n",
      "<DirEntry '193'>\n",
      "<DirEntry '701'>\n",
      "<DirEntry '136'>\n",
      "<DirEntry '869'>\n",
      "<DirEntry '947'>\n",
      "<DirEntry '712'>\n",
      "<DirEntry '660'>\n",
      "<DirEntry '303'>\n",
      "<DirEntry '925'>\n",
      "<DirEntry '316'>\n",
      "<DirEntry '856'>\n",
      "<DirEntry '293'>\n",
      "<DirEntry '150'>\n",
      "<DirEntry '592'>\n",
      "<DirEntry '013'>\n",
      "<DirEntry '080'>\n",
      "<DirEntry '989'>\n",
      "<DirEntry '180'>\n",
      "<DirEntry '475'>\n",
      "<DirEntry '170'>\n",
      "<DirEntry '702'>\n",
      "<DirEntry '246'>\n",
      "<DirEntry '032'>\n",
      "<DirEntry '596'>\n",
      "<DirEntry '191'>\n",
      "<DirEntry '195'>\n",
      "<DirEntry '292'>\n",
      "<DirEntry '870'>\n",
      "<DirEntry '121'>\n",
      "<DirEntry '902'>\n",
      "<DirEntry '326'>\n",
      "<DirEntry '266'>\n",
      "<DirEntry '152'>\n",
      "<DirEntry '341'>\n",
      "<DirEntry '353'>\n",
      "<DirEntry '848'>\n",
      "<DirEntry '686'>\n",
      "<DirEntry '542'>\n",
      "<DirEntry '308'>\n",
      "<DirEntry '124'>\n",
      "<DirEntry '628'>\n",
      "<DirEntry '071'>\n",
      "<DirEntry '286'>\n",
      "<DirEntry '440'>\n",
      "<DirEntry '948'>\n",
      "<DirEntry '792'>\n",
      "<DirEntry '127'>\n",
      "<DirEntry '064'>\n",
      "<DirEntry '487'>\n",
      "<DirEntry '156'>\n",
      "<DirEntry '770'>\n",
      "<DirEntry '048'>\n",
      "<DirEntry '671'>\n",
      "<DirEntry '296'>\n",
      "<DirEntry '251'>\n",
      "<DirEntry '903'>\n",
      "<DirEntry '498'>\n",
      "<DirEntry '815'>\n",
      "<DirEntry '077'>\n",
      "<DirEntry '508'>\n",
      "<DirEntry '084'>\n",
      "<DirEntry '874'>\n",
      "<DirEntry '748'>\n",
      "<DirEntry '723'>\n",
      "<DirEntry '318'>\n",
      "<DirEntry '349'>\n",
      "<DirEntry '089'>\n",
      "<DirEntry '969'>\n",
      "<DirEntry '388'>\n",
      "<DirEntry '562'>\n",
      "<DirEntry '294'>\n",
      "<DirEntry '016'>\n",
      "<DirEntry '342'>\n",
      "<DirEntry '764'>\n",
      "<DirEntry '065'>\n",
      "<DirEntry '334'>\n",
      "<DirEntry '087'>\n",
      "<DirEntry '476'>\n",
      "<DirEntry '910'>\n",
      "<DirEntry '861'>\n",
      "<DirEntry '981'>\n",
      "<DirEntry '649'>\n",
      "<DirEntry '045'>\n",
      "<DirEntry '203'>\n",
      "<DirEntry '928'>\n",
      "<DirEntry '965'>\n",
      "<DirEntry '849'>\n",
      "<DirEntry '865'>\n",
      "<DirEntry '892'>\n",
      "<DirEntry '707'>\n",
      "<DirEntry '675'>\n",
      "<DirEntry '672'>\n",
      "<DirEntry '494'>\n",
      "<DirEntry '381'>\n",
      "<DirEntry '392'>\n",
      "<DirEntry '699'>\n",
      "<DirEntry '836'>\n",
      "<DirEntry '806'>\n",
      "<DirEntry '402'>\n",
      "<DirEntry '554'>\n",
      "<DirEntry '510'>\n",
      "<DirEntry '470'>\n",
      "<DirEntry '716'>\n",
      "<DirEntry '135'>\n",
      "<DirEntry '012'>\n",
      "<DirEntry '137'>\n",
      "FaceShifter\n",
      "Finish writing FF-FH.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_root_path = \"/mnt/sdc/maisie/\"\n",
    "compression_level = \"c23\"\n",
    "output_file_path  = \"/mnt/sdb/maisie/SelfBlendedImages/data\"\n",
    "\n",
    "ff_dict = {\n",
    "    \"Real\": \"FF-real\",\n",
    "    \"FaceShifter\": \"FF-FH\",\n",
    "}\n",
    "\n",
    "# Load the JSON files for data split\n",
    "dataset_path = os.path.join(dataset_root_path, \"FaceForensics++\")\n",
    "\n",
    "# Load the JSON files for data split\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(\n",
    "                dataset_path,\n",
    "                \"train.json\",\n",
    "            )),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    train_json = json.load(f)\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(dataset_path,\"val.json\")),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    val_json = json.load(f)\n",
    "with open(\n",
    "        file=os.path.join(\n",
    "            os.path.join(dataset_path,\"test.json\")),\n",
    "        mode=\"r\",\n",
    ") as f:\n",
    "    test_json = json.load(f)\n",
    "video_to_mode = dict()\n",
    "for d1, d2 in train_json:\n",
    "    video_to_mode[d1] = \"train\"\n",
    "    video_to_mode[d2] = \"train\"\n",
    "    video_to_mode[d1 + \"_\" + d2] = \"train\"\n",
    "    video_to_mode[d2 + \"_\" + d1] = \"train\"\n",
    "for d1, d2 in val_json:\n",
    "    video_to_mode[d1] = 'train'\n",
    "    video_to_mode[d2] = 'train'\n",
    "    video_to_mode[d1+'_'+d2] = 'train'\n",
    "    video_to_mode[d2+'_'+d1] = 'train'\n",
    "for d1, d2 in test_json:\n",
    "    video_to_mode[d1] = 'test'\n",
    "    video_to_mode[d2] = 'test'\n",
    "    video_to_mode[d1+'_'+d2] = 'test'\n",
    "    video_to_mode[d2+'_'+d1] = 'test'\n",
    "\n",
    "dataset_dict = {}\n",
    "\n",
    "# FaceForensics++ real dataset\n",
    "label = \"Real\"\n",
    "dataset_dict[\"FaceForensics++\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"] = {}\n",
    "\n",
    "# Iterate over all compression levels: c23, c40, raw\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"train\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"test\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"val\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"train\"][compression_level] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"test\"][compression_level] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\"FF-real\"][\"val\"][compression_level] = {}\n",
    "\n",
    "# Iterate over all videos\n",
    "for video_path in os.scandir(\n",
    "        os.path.join(\n",
    "            dataset_path,\n",
    "            \"original_sequences\",\n",
    "            \"youtube\",\n",
    "            compression_level,\n",
    "            \"rawframes\",\n",
    "        )):\n",
    "    if video_path.is_dir() and 'ipynb' not in video_path.name:\n",
    "        video_name = video_path.name\n",
    "        mode = video_to_mode[video_name]\n",
    "        print(video_path)\n",
    "        frame_paths = [\n",
    "            os.path.join(video_path, frame.name)\n",
    "            for frame in os.scandir(video_path) if '_' in frame.name\n",
    "        ]\n",
    "        dataset_dict[\"FaceForensics++\"][\"FF-real\"][mode][compression_level][video_name] = {\n",
    "                \"label\": ff_dict[label],\n",
    "                \"frames\": frame_paths\n",
    "            }\n",
    "\n",
    "\n",
    "# FaceForensics++ fake datasets\n",
    "label = \"FaceShifter\"\n",
    "print(label)\n",
    "dataset_dict[\"FaceForensics++\"][ff_dict[label]] = {}\n",
    "dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"train\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"test\"] = {}\n",
    "dataset_dict[\"FaceForensics++\"][ff_dict[label]][\"val\"] = {}\n",
    "\n",
    "dataset_dict[\"FaceForensics++\"][\n",
    "    ff_dict[label]][\"train\"][compression_level] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\n",
    "    ff_dict[label]][\"test\"][compression_level] = {}\n",
    "dataset_dict[\"FaceForensics++\"][\n",
    "    ff_dict[label]][\"val\"][compression_level] = {}\n",
    "\n",
    "# Iterate over all videos\n",
    "for video_path in os.scandir(\n",
    "        os.path.join(\n",
    "            dataset_path,\n",
    "            \"manipulated_sequences\",\n",
    "            label,\n",
    "            compression_level,\n",
    "            \"rawframes\",\n",
    "        )):\n",
    "    \n",
    "    if video_path.is_dir() and 'ipynb' not in video_path.name:\n",
    "        video_name = video_path.name\n",
    "        mode = video_to_mode[video_name]\n",
    "        frame_paths = [\n",
    "            os.path.join(video_path, frame.name)\n",
    "            for frame in os.scandir(video_path) if '_' in frame.name\n",
    "        ]\n",
    "\n",
    "        dataset_dict[\"FaceForensics++\"][ff_dict[label]][mode][compression_level][\n",
    "            video_name] = {\n",
    "                \"label\": ff_dict[label],\n",
    "                \"frames\": frame_paths \n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for label, value in dataset_dict[\"FaceForensics++\"].items():\n",
    "    if label != \"FF-real\":\n",
    "        with open(os.path.join(output_file_path, f\"{label}.json\"),\n",
    "                    \"w\") as f:\n",
    "            data = {\n",
    "                label: {\n",
    "                    \"FF-real\": dataset_dict[\"FaceForensics++\"][\"FF-real\"],\n",
    "                    label: value,\n",
    "                }\n",
    "            }\n",
    "            json.dump(data, f)\n",
    "            print(f\"Finish writing {label}.json\")\n",
    "\n",
    "# with open(os.path.join(output_file_path, \"FF-FH.json\"), \"w\") as f:\n",
    "#     json.dump(dataset_dict, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
